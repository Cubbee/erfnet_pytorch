{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/heumchri/erfnet_pytorch/blob/master/testPretrainedERFNet.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "WPmTvrCSU42W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# general"
      ]
    },
    {
      "metadata": {
        "id": "shHCBH0iJewE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ENklW_Q4g207",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## utilization monitoring"
      ]
    },
    {
      "metadata": {
        "id": "LFOeJjrChDec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#requirements for gpu and ram usage\n",
        "\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9ClMeG-VIfn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#gpu and ram usage\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NsibX7-1hDeg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#running processes\n",
        "\n",
        "#!ps -aux\n",
        "!ps -aux | grep python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVThw0JoIjDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#storage usage\n",
        "\n",
        "!df -h "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugsppsq0fKlS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## increase shm for multithreading to work"
      ]
    },
    {
      "metadata": {
        "id": "L7cut4qWKEgL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /etc/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4EMrBeJdNV0b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%writefile fstab\n",
        "tmpfs /dev/shm tmpfs defaults,size=4G 0 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uEhKvrc4NikO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mount -o remount /dev/shm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNMu-qwjkqLk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#storage usage\n",
        "\n",
        "!df -h "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZ9YgkO1HIQS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## mount google drive"
      ]
    },
    {
      "metadata": {
        "id": "zOc4Mdw7HJ6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vdkxblGwHR3i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8grQFFcYICZa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dwlWt0DiIEQ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vB-7eeC63FMm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install requirements"
      ]
    },
    {
      "metadata": {
        "id": "UrlaSAp1Gt6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iwuIW56WEEK7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install numpy matplotlib torchvision Pillow visdom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0yla5tY43MSm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# clone repo"
      ]
    },
    {
      "metadata": {
        "id": "T3KONFD0Dw1T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/heumchri/erfnet_pytorch.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G-k3X9VURtu_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nVn_g0mlR0KX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "--Mhfpls9Ejg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test forward time\n",
        "20 classes:\n",
        "\n",
        "decoder batch 1: 0.101\n",
        "\n",
        "decoder batch 16: 0.071\n",
        "\n",
        "encoder batch 1: 0.070\n",
        "\n",
        "encoder batch 16: 0.049\n",
        "\n",
        "binary: \n",
        "\n",
        "decoder batch 1: 0.098\n",
        "\n",
        "decoder batch 16: 0.069\n",
        "\n",
        "encoder batch 1: 0.070\n",
        "\n",
        "encoder batch 16: 0.049"
      ]
    },
    {
      "metadata": {
        "id": "yMqZ3g63_TPl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/eval/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BnDRPxrJms9j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 eval_forwardTime.py --batch-size 1 --classes 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qOZUreUTrqtF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 eval_forwardTime.py --batch-size 1 --classes 20 --onlyEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oprehLyzx2mv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test pretrained model (val dataset, nn upsampling) 0.976"
      ]
    },
    {
      "metadata": {
        "id": "NvTRp4dyx2mw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/eval/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GQjU0iakx2my",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python eval_cityscapes_server.py --datadir /content/datasets/cityscapes/ --subset val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "raHTu9Tnx2m0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "Rndn0tDnx2m1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('./save_results/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3tuWRhZax2m-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "WbdCBrZqx2m_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/erfnet_pytorch/eval/save_results/val/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MGMCSnIcx2nA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G0kAMrYmx2nB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1AxCmXu3RoDo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test pretrained model (val dataset, bilinear upsampling) 0.976"
      ]
    },
    {
      "metadata": {
        "id": "KfposPisRoDp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/eval/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m7KGIbKLaF9B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import importlib\n",
        "\n",
        "from PIL import Image\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, CenterCrop, Normalize, Resize\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "from dataset import cityscapes\n",
        "from erfnet import ERFNet\n",
        "from transform import Relabel, ToLabel, Colorize\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_CLASSES = 20\n",
        "\n",
        "image_transform = ToPILImage()\n",
        "input_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToTensor(),\n",
        "    #Normalize([.485, .456, .406], [.229, .224, .225]),\n",
        "])\n",
        "target_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToLabel(),\n",
        "    Relabel(255, 19),   #ignore label to 19\n",
        "])\n",
        "\n",
        "cityscapes_trainIds2labelIds = Compose([\n",
        "    Relabel(19, 255),  \n",
        "    Relabel(18, 33),\n",
        "    Relabel(17, 32),\n",
        "    Relabel(16, 31),\n",
        "    Relabel(15, 28),\n",
        "    Relabel(14, 27),\n",
        "    Relabel(13, 26),\n",
        "    Relabel(12, 25),\n",
        "    Relabel(11, 24),\n",
        "    Relabel(10, 23),\n",
        "    Relabel(9, 22),\n",
        "    Relabel(8, 21),\n",
        "    Relabel(7, 20),\n",
        "    Relabel(6, 19),\n",
        "    Relabel(5, 17),\n",
        "    Relabel(4, 13),\n",
        "    Relabel(3, 12),\n",
        "    Relabel(2, 11),\n",
        "    Relabel(1, 8),\n",
        "    Relabel(0, 7),\n",
        "    Relabel(255, 0),\n",
        "    ToPILImage(),\n",
        "    #Resize(1024, Image.NEAREST),\n",
        "])\n",
        "def evalDecoderValset():\n",
        "    up = torch.nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "    up = up.cuda()\n",
        "\n",
        "    modelpath = \"../trained_models/\" + \"erfnet.py\"\n",
        "    weightspath = \"../trained_models/\" + \"erfnet_pretrained.pth\"\n",
        "\n",
        "    print (\"Loading model: \" + modelpath)\n",
        "    print (\"Loading weights: \" + weightspath)\n",
        "\n",
        "    #Import ERFNet model from the folder\n",
        "    #Net = importlib.import_module(modelpath.replace(\"/\", \".\"), \"ERFNet\")\n",
        "    model = ERFNet(NUM_CLASSES)\n",
        "\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    if (not False):\n",
        "        model = model.cuda()\n",
        "\n",
        "    #model.load_state_dict(torch.load(args.state))\n",
        "    #model.load_state_dict(torch.load(weightspath)) #not working if missing key\n",
        "\n",
        "    def load_my_state_dict(model, state_dict):  #custom function to load model when not all dict elements\n",
        "        own_state = model.state_dict()\n",
        "        for name, param in state_dict.items():\n",
        "            if name not in own_state:\n",
        "                 continue\n",
        "            own_state[name].copy_(param)\n",
        "        return model\n",
        "\n",
        "    model = load_my_state_dict(model, torch.load(weightspath))\n",
        "    print (\"Model and weights LOADED successfully\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if(not os.path.exists(\"/content/datasets/cityscapes/\")):\n",
        "        print (\"Error: datadir could not be loaded\")\n",
        "\n",
        "\n",
        "    loader = DataLoader(cityscapes(\"/content/datasets/cityscapes/\", input_transform_cityscapes, target_transform_cityscapes, subset=\"val\"),\n",
        "        num_workers=4, batch_size=1, shuffle=False)\n",
        "\n",
        "    for step, (images, labels, filename, filenameGt) in enumerate(loader):\n",
        "        \n",
        "        if (not False):\n",
        "            images = images.cuda()\n",
        "            #labels = labels.cuda()\n",
        "\n",
        "        inputs = Variable(images, volatile=True)\n",
        "        #targets = Variable(labels, volatile=True)\n",
        "        outputs = model(inputs,only_encode=False)\n",
        "        outputs = up(outputs)\n",
        "\n",
        "        label = outputs[0].max(0)[1].byte().cpu().data\n",
        "        label_cityscapes = cityscapes_trainIds2labelIds(label.unsqueeze(0))\n",
        "        #print (numpy.unique(label.numpy()))  #debug\n",
        "\n",
        "        filenameSave = \"./save_results/\" + filename[0].split(\"leftImg8bit/\")[1]\n",
        "        os.makedirs(os.path.dirname(filenameSave), exist_ok=True)\n",
        "        #image_transform(label.byte()).save(filenameSave)\n",
        "        label_cityscapes.save(filenameSave)\n",
        "\n",
        "        print (step, filenameSave)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D1QXucTrbQuI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evalDecoderValset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DqOEUlmCRoDr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "BH0heuu6RoDs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('./save_results/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ZuihRdrRoDt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "rQrE9kcgRoDu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/erfnet_pytorch/eval/save_results/val/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uz-V4VyARoDu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8zxh7NERoDw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RjMrzslfP8O_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test 20 classes retrained model (val dataset, nn upsampling) 0.976"
      ]
    },
    {
      "metadata": {
        "id": "j0QEfH6VP8O_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/eval/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJW9zCHfP8PC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import importlib\n",
        "\n",
        "from PIL import Image\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, CenterCrop, Normalize, Resize\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "from dataset import cityscapes\n",
        "from erfnet import ERFNet\n",
        "from transform import Relabel, ToLabel, Colorize\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_CLASSES = 20\n",
        "\n",
        "image_transform = ToPILImage()\n",
        "input_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToTensor(),\n",
        "    #Normalize([.485, .456, .406], [.229, .224, .225]),\n",
        "])\n",
        "target_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToLabel(),\n",
        "    Relabel(255, 19),   #ignore label to 19\n",
        "])\n",
        "\n",
        "cityscapes_trainIds2labelIds = Compose([\n",
        "    Relabel(19, 255),  \n",
        "    Relabel(18, 33),\n",
        "    Relabel(17, 32),\n",
        "    Relabel(16, 31),\n",
        "    Relabel(15, 28),\n",
        "    Relabel(14, 27),\n",
        "    Relabel(13, 26),\n",
        "    Relabel(12, 25),\n",
        "    Relabel(11, 24),\n",
        "    Relabel(10, 23),\n",
        "    Relabel(9, 22),\n",
        "    Relabel(8, 21),\n",
        "    Relabel(7, 20),\n",
        "    Relabel(6, 19),\n",
        "    Relabel(5, 17),\n",
        "    Relabel(4, 13),\n",
        "    Relabel(3, 12),\n",
        "    Relabel(2, 11),\n",
        "    Relabel(1, 8),\n",
        "    Relabel(0, 7),\n",
        "    Relabel(255, 0),\n",
        "    ToPILImage(),\n",
        "    #Resize(1024, Image.NEAREST),\n",
        "])\n",
        "def evalDecoderValset():\n",
        "    up = torch.nn.Upsample(scale_factor=2, mode='nearest')\n",
        "    up = up.cuda()\n",
        "\n",
        "    modelpath = \"../trained_models/\" + \"erfnet.py\"\n",
        "    weightspath = \"/content/drive/erfnet_checkpoints/pretrainedenc20classes/\" + \"model_best.pth\"\n",
        "\n",
        "    print (\"Loading model: \" + modelpath)\n",
        "    print (\"Loading weights: \" + weightspath)\n",
        "\n",
        "    #Import ERFNet model from the folder\n",
        "    #Net = importlib.import_module(modelpath.replace(\"/\", \".\"), \"ERFNet\")\n",
        "    model = ERFNet(NUM_CLASSES)\n",
        "\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    if (not False):\n",
        "        model = model.cuda()\n",
        "\n",
        "    #model.load_state_dict(torch.load(args.state))\n",
        "    #model.load_state_dict(torch.load(weightspath)) #not working if missing key\n",
        "\n",
        "    def load_my_state_dict(model, state_dict):  #custom function to load model when not all dict elements\n",
        "        own_state = model.state_dict()\n",
        "        for name, param in state_dict.items():\n",
        "            if name not in own_state:\n",
        "                 continue\n",
        "            own_state[name].copy_(param)\n",
        "        return model\n",
        "\n",
        "    model = load_my_state_dict(model, torch.load(weightspath))\n",
        "    print (\"Model and weights LOADED successfully\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if(not os.path.exists(\"/content/datasets/cityscapes/\")):\n",
        "        print (\"Error: datadir could not be loaded\")\n",
        "\n",
        "\n",
        "    loader = DataLoader(cityscapes(\"/content/datasets/cityscapes/\", input_transform_cityscapes, target_transform_cityscapes, subset=\"val\"),\n",
        "        num_workers=4, batch_size=1, shuffle=False)\n",
        "\n",
        "    for step, (images, labels, filename, filenameGt) in enumerate(loader):\n",
        "        \n",
        "        if (not False):\n",
        "            images = images.cuda()\n",
        "            #labels = labels.cuda()\n",
        "\n",
        "        inputs = Variable(images, volatile=True)\n",
        "        #targets = Variable(labels, volatile=True)\n",
        "        outputs = model(inputs,only_encode=False)\n",
        "        outputs = up(outputs)\n",
        "\n",
        "        label = outputs[0].max(0)[1].byte().cpu().data\n",
        "        label_cityscapes = cityscapes_trainIds2labelIds(label.unsqueeze(0))\n",
        "        #print (numpy.unique(label.numpy()))  #debug\n",
        "\n",
        "        filenameSave = \"./save_results/\" + filename[0].split(\"leftImg8bit/\")[1]\n",
        "        os.makedirs(os.path.dirname(filenameSave), exist_ok=True)\n",
        "        #image_transform(label.byte()).save(filenameSave)\n",
        "        label_cityscapes.save(filenameSave)\n",
        "\n",
        "        print (step, filenameSave)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cvjfMFGOP8PD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evalDecoderValset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wvuera5VP8PE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "otIU4zJvP8PF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('./save_results/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nfJllVENP8PG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "MzyOT0COP8PH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/erfnet_pytorch/eval/save_results/val/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s61soTMEP8PI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VLMrHX6nP8PK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWVCLifvMaht",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test 20 classes retrained model (val dataset, bilinear upsampling) 0.976"
      ]
    },
    {
      "metadata": {
        "id": "fyd7G-zSMahu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/eval/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5H32ir-cMahw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import importlib\n",
        "\n",
        "from PIL import Image\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, CenterCrop, Normalize, Resize\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "from dataset import cityscapes\n",
        "from erfnet import ERFNet\n",
        "from transform import Relabel, ToLabel, Colorize\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_CLASSES = 20\n",
        "\n",
        "image_transform = ToPILImage()\n",
        "input_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToTensor(),\n",
        "    #Normalize([.485, .456, .406], [.229, .224, .225]),\n",
        "])\n",
        "target_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToLabel(),\n",
        "    Relabel(255, 19),   #ignore label to 19\n",
        "])\n",
        "\n",
        "cityscapes_trainIds2labelIds = Compose([\n",
        "    Relabel(19, 255),  \n",
        "    Relabel(18, 33),\n",
        "    Relabel(17, 32),\n",
        "    Relabel(16, 31),\n",
        "    Relabel(15, 28),\n",
        "    Relabel(14, 27),\n",
        "    Relabel(13, 26),\n",
        "    Relabel(12, 25),\n",
        "    Relabel(11, 24),\n",
        "    Relabel(10, 23),\n",
        "    Relabel(9, 22),\n",
        "    Relabel(8, 21),\n",
        "    Relabel(7, 20),\n",
        "    Relabel(6, 19),\n",
        "    Relabel(5, 17),\n",
        "    Relabel(4, 13),\n",
        "    Relabel(3, 12),\n",
        "    Relabel(2, 11),\n",
        "    Relabel(1, 8),\n",
        "    Relabel(0, 7),\n",
        "    Relabel(255, 0),\n",
        "    ToPILImage(),\n",
        "    #Resize(1024, Image.NEAREST),\n",
        "])\n",
        "def evalDecoderValset():\n",
        "    up = torch.nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "    up = up.cuda()\n",
        "\n",
        "    modelpath = \"../trained_models/\" + \"erfnet.py\"\n",
        "    weightspath = \"/content/drive/erfnet_checkpoints/pretrainedenc20classes/\" + \"model_best.pth\"\n",
        "\n",
        "    print (\"Loading model: \" + modelpath)\n",
        "    print (\"Loading weights: \" + weightspath)\n",
        "\n",
        "    #Import ERFNet model from the folder\n",
        "    #Net = importlib.import_module(modelpath.replace(\"/\", \".\"), \"ERFNet\")\n",
        "    model = ERFNet(NUM_CLASSES)\n",
        "\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    if (not False):\n",
        "        model = model.cuda()\n",
        "\n",
        "    #model.load_state_dict(torch.load(args.state))\n",
        "    #model.load_state_dict(torch.load(weightspath)) #not working if missing key\n",
        "\n",
        "    def load_my_state_dict(model, state_dict):  #custom function to load model when not all dict elements\n",
        "        own_state = model.state_dict()\n",
        "        for name, param in state_dict.items():\n",
        "            if name not in own_state:\n",
        "                 continue\n",
        "            own_state[name].copy_(param)\n",
        "        return model\n",
        "\n",
        "    model = load_my_state_dict(model, torch.load(weightspath))\n",
        "    print (\"Model and weights LOADED successfully\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if(not os.path.exists(\"/content/datasets/cityscapes/\")):\n",
        "        print (\"Error: datadir could not be loaded\")\n",
        "\n",
        "\n",
        "    loader = DataLoader(cityscapes(\"/content/datasets/cityscapes/\", input_transform_cityscapes, target_transform_cityscapes, subset=\"val\"),\n",
        "        num_workers=4, batch_size=1, shuffle=False)\n",
        "\n",
        "    for step, (images, labels, filename, filenameGt) in enumerate(loader):\n",
        "        \n",
        "        if (not False):\n",
        "            images = images.cuda()\n",
        "            #labels = labels.cuda()\n",
        "\n",
        "        inputs = Variable(images, volatile=True)\n",
        "        #targets = Variable(labels, volatile=True)\n",
        "        outputs = model(inputs,only_encode=False)\n",
        "        outputs = up(outputs)\n",
        "\n",
        "        label = outputs[0].max(0)[1].byte().cpu().data\n",
        "        label_cityscapes = cityscapes_trainIds2labelIds(label.unsqueeze(0))\n",
        "        #print (numpy.unique(label.numpy()))  #debug\n",
        "\n",
        "        filenameSave = \"./save_results/\" + filename[0].split(\"leftImg8bit/\")[1]\n",
        "        os.makedirs(os.path.dirname(filenameSave), exist_ok=True)\n",
        "        #image_transform(label.byte()).save(filenameSave)\n",
        "        label_cityscapes.save(filenameSave)\n",
        "\n",
        "        print (step, filenameSave)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EKTPb0AhMahx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evalDecoderValset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oj_pIh3sMahz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "dS8famvHMahz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('./save_results/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kN4KqPebMah2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "TCy1UBrgMah2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/erfnet_pytorch/eval/save_results/val/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cL6ghoCqMah4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DKMwBks6Mah6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ESfZ8AsnqwK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test pretrained model (val dataset, nn upsampling, only encoder) 0.070"
      ]
    },
    {
      "metadata": {
        "id": "tGX2YmsfnqwL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/eval/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3vZ-pvDbnqwO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python eval_cityscapes_server.py --datadir /content/datasets/cityscapes/ --subset val --onlyEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y50lOHq8nqwO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "z9yRtiPynqwO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('./save_results/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ag7de4g1nqwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "YxUiXYEinqwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/erfnet_pytorch/eval/save_results/val/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t2O6kaS5nqwQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "egyNztjgnqwQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LmZgGDv9oZ-E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test pretrained model (val dataset, bilinear upsampling, only encoder) 0.049"
      ]
    },
    {
      "metadata": {
        "id": "246D764toZ-E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/eval/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_CjjvIqIoZ-F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import importlib\n",
        "\n",
        "from PIL import Image\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, CenterCrop, Normalize, Resize\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "from dataset import cityscapes\n",
        "from erfnet import ERFNet\n",
        "from transform import Relabel, ToLabel, Colorize\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_CLASSES = 20\n",
        "\n",
        "image_transform = ToPILImage()\n",
        "input_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToTensor(),\n",
        "    #Normalize([.485, .456, .406], [.229, .224, .225]),\n",
        "])\n",
        "target_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToLabel(),\n",
        "    Relabel(255, 19),   #ignore label to 19\n",
        "])\n",
        "\n",
        "cityscapes_trainIds2labelIds = Compose([\n",
        "    Relabel(19, 255),  \n",
        "    Relabel(18, 33),\n",
        "    Relabel(17, 32),\n",
        "    Relabel(16, 31),\n",
        "    Relabel(15, 28),\n",
        "    Relabel(14, 27),\n",
        "    Relabel(13, 26),\n",
        "    Relabel(12, 25),\n",
        "    Relabel(11, 24),\n",
        "    Relabel(10, 23),\n",
        "    Relabel(9, 22),\n",
        "    Relabel(8, 21),\n",
        "    Relabel(7, 20),\n",
        "    Relabel(6, 19),\n",
        "    Relabel(5, 17),\n",
        "    Relabel(4, 13),\n",
        "    Relabel(3, 12),\n",
        "    Relabel(2, 11),\n",
        "    Relabel(1, 8),\n",
        "    Relabel(0, 7),\n",
        "    Relabel(255, 0),\n",
        "    ToPILImage(),\n",
        "    #Resize(1024, Image.NEAREST),\n",
        "])\n",
        "def evalEncoderValset():\n",
        "    up = torch.nn.Upsample(scale_factor=16, mode='bilinear')\n",
        "    up = up.cuda()\n",
        "\n",
        "    modelpath = \"../trained_models/\" + \"erfnet.py\"\n",
        "    weightspath = \"../trained_models/\" + \"erfnet_pretrained.pth\"\n",
        "\n",
        "    print (\"Loading model: \" + modelpath)\n",
        "    print (\"Loading weights: \" + weightspath)\n",
        "\n",
        "    #Import ERFNet model from the folder\n",
        "    #Net = importlib.import_module(modelpath.replace(\"/\", \".\"), \"ERFNet\")\n",
        "    model = ERFNet(NUM_CLASSES)\n",
        "\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    if (not False):\n",
        "        model = model.cuda()\n",
        "\n",
        "    #model.load_state_dict(torch.load(args.state))\n",
        "    #model.load_state_dict(torch.load(weightspath)) #not working if missing key\n",
        "\n",
        "    def load_my_state_dict(model, state_dict):  #custom function to load model when not all dict elements\n",
        "        own_state = model.state_dict()\n",
        "        for name, param in state_dict.items():\n",
        "            if name not in own_state:\n",
        "                 continue\n",
        "            own_state[name].copy_(param)\n",
        "        return model\n",
        "\n",
        "    model = load_my_state_dict(model, torch.load(weightspath))\n",
        "    print (\"Model and weights LOADED successfully\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if(not os.path.exists(\"/content/datasets/cityscapes/\")):\n",
        "        print (\"Error: datadir could not be loaded\")\n",
        "\n",
        "\n",
        "    loader = DataLoader(cityscapes(\"/content/datasets/cityscapes/\", input_transform_cityscapes, target_transform_cityscapes, subset=\"val\"),\n",
        "        num_workers=4, batch_size=1, shuffle=False)\n",
        "\n",
        "    for step, (images, labels, filename, filenameGt) in enumerate(loader):\n",
        "        \n",
        "        if (not False):\n",
        "            images = images.cuda()\n",
        "            #labels = labels.cuda()\n",
        "\n",
        "        inputs = Variable(images, volatile=True)\n",
        "        #targets = Variable(labels, volatile=True)\n",
        "        outputs = model(inputs,only_encode=True)\n",
        "        outputs = up(outputs)\n",
        "\n",
        "        label = outputs[0].max(0)[1].byte().cpu().data\n",
        "        label_cityscapes = cityscapes_trainIds2labelIds(label.unsqueeze(0))\n",
        "        #print (numpy.unique(label.numpy()))  #debug\n",
        "\n",
        "        filenameSave = \"./save_results/\" + filename[0].split(\"leftImg8bit/\")[1]\n",
        "        os.makedirs(os.path.dirname(filenameSave), exist_ok=True)\n",
        "        #image_transform(label.byte()).save(filenameSave)\n",
        "        label_cityscapes.save(filenameSave)\n",
        "\n",
        "        print (step, filenameSave)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XLcIORS2oZ-G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evalEncoderValset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1bkFf6JxoZ-I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "vld1vJ1-oZ-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('./save_results/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DQH0t3r_oZ-J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "b_7VG1jFoZ-J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/erfnet_pytorch/eval/save_results/val/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V_FcU1IMoZ-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ghwQGbPLoZ-L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8aC7tRoqLuEx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test retrained encoder (val dataset, nn upsampling, only encoder) 0.952\n",
        "\n",
        "**01_batch-size6,epoch 135(best,0.9471): 0.947**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**07_batch-size6_weighted,epoch 148(best,0.9399): 0.946**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**08_batch-size6_2,epoch 129(best,0.9473): 0.952**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**12_fullsizeeval_ignorebackground,epoch 8(best,0.9782): 0.935**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**09_batch-size12,epoch 143(best,0.9474): 0.950**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**13_ignorebackground,epoch 20(best,0.9818): 0.935**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**10_batch-size6_3,epoch 41(best,0.9477): 0.940**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**11_trainInOneGo_encoder,epoch 133(best,0.9518): 0.951**\n",
        "\n",
        "---\n",
        "\n",
        "**14_fullsizeeval_roadval,epoch 59(best,0.9136): 0.942**\n",
        "\n",
        "---\n",
        "\n",
        "**21_batch-size6_weighted_new,epoch 143(best,0.9483): 0.951**\n",
        "\n",
        "---\n",
        "\n",
        "**22_batch-size6_roadval_weighted_new,epoch 135(best,0.9311): 0.949**"
      ]
    },
    {
      "metadata": {
        "id": "cMo6DJr-t8vf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/eval/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CVG9cCbULuEz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import importlib\n",
        "\n",
        "from PIL import Image\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, CenterCrop, Normalize, Resize\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "from dataset import cityscapes\n",
        "from erfnet import ERFNet\n",
        "from transform import Relabel, ToLabel, Colorize\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "image_transform = ToPILImage()\n",
        "input_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToTensor(),\n",
        "    #Normalize([.485, .456, .406], [.229, .224, .225]),\n",
        "])\n",
        "target_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToLabel(),\n",
        "    Relabel(255, 19),   #ignore label to 19\n",
        "])\n",
        "\n",
        "cityscapes_trainIds2labelIds = Compose([\n",
        "    Relabel(0, 7),\n",
        "    Relabel(1, 0),\n",
        "    ToPILImage(),\n",
        "    #Resize(1024, Image.NEAREST),\n",
        "])\n",
        "def evalEncoderValset():\n",
        "    up = torch.nn.Upsample(scale_factor=16, mode='nearest')\n",
        "    up = up.cuda()\n",
        "\n",
        "    modelpath = \"/content/erfnet_pytorch/trained_models/\" + \"erfnet.py\"\n",
        "    weightspath = \"/content/drive/erfnet_checkpoints/21_batch-size6_weighted_new/\" + \"model_encoder_best.pth\"\n",
        "\n",
        "    print (\"Loading model: \" + modelpath)\n",
        "    print (\"Loading weights: \" + weightspath)\n",
        "\n",
        "    #Import ERFNet model from the folder\n",
        "    #Net = importlib.import_module(modelpath.replace(\"/\", \".\"), \"ERFNet\")\n",
        "    model = ERFNet(NUM_CLASSES)\n",
        "\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    if (not False):\n",
        "        model = model.cuda()\n",
        "\n",
        "    #model.load_state_dict(torch.load(args.state))\n",
        "    #model.load_state_dict(torch.load(weightspath)) #not working if missing key\n",
        "\n",
        "    def load_my_state_dict(model, state_dict):  #custom function to load model when not all dict elements\n",
        "        own_state = model.state_dict()\n",
        "        for name, param in state_dict.items():\n",
        "            if name not in own_state:\n",
        "                 continue\n",
        "            own_state[name].copy_(param)\n",
        "        return model\n",
        "\n",
        "    model = load_my_state_dict(model, torch.load(weightspath))\n",
        "    print (\"Model and weights LOADED successfully\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if(not os.path.exists(\"/content/datasets/cityscapes/\")):\n",
        "        print (\"Error: datadir could not be loaded\")\n",
        "\n",
        "\n",
        "    loader = DataLoader(cityscapes(\"/content/datasets/cityscapes/\", input_transform_cityscapes, target_transform_cityscapes, subset=\"val\"),\n",
        "        num_workers=4, batch_size=1, shuffle=False)\n",
        "\n",
        "    for step, (images, labels, filename, filenameGt) in enumerate(loader):\n",
        "        \n",
        "        if (not False):\n",
        "            images = images.cuda()\n",
        "            #labels = labels.cuda()\n",
        "\n",
        "        inputs = Variable(images, volatile=True)\n",
        "        #targets = Variable(labels, volatile=True)\n",
        "        outputs = model(inputs,only_encode=True)\n",
        "        outputs = up(outputs)\n",
        "\n",
        "        label = outputs[0].max(0)[1].byte().cpu().data\n",
        "        label_cityscapes = cityscapes_trainIds2labelIds(label.unsqueeze(0))\n",
        "        #print (numpy.unique(label.numpy()))  #debug\n",
        "\n",
        "        filenameSave = \"/content/erfnet_pytorch/eval/save_results/\" + filename[0].split(\"leftImg8bit/\")[1]\n",
        "        os.makedirs(os.path.dirname(filenameSave), exist_ok=True)\n",
        "        #image_transform(label.byte()).save(filenameSave)\n",
        "        label_cityscapes.save(filenameSave)\n",
        "\n",
        "        print (step, filenameSave)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vAr2Vv4CLuEz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evalEncoderValset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UGE8HmoPLuE1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "M5jBHTxdLuE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('/content/erfnet_pytorch/eval/save_results/val/munster/munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gaQ2645PLuE1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "CYCCawfALuE2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/erfnet_pytorch/eval/save_results/val/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nAruDfveLuE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A1gJGePaLuE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xEbA0qKkuJbx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test retrained encoder (val dataset, bilinear upsampling, only encoder) 0.963\n",
        "**01_batch-size6,epoch 16: 0.949**\n",
        "\n",
        "**01_batch-size6,epoch 38: 0.954**\n",
        "\n",
        "**01_batch-size6,epoch 135 (best,0.9471):  0.958**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**07_batch-size6_weighted,epoch 148(best,0.9399): 0.955**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**08_batch-size6_2,epoch 129(best,0.9473): 0.963**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**12_fullsizeeval_ignorebackground,epoch 8(best,0.9782): 0.942**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**09_batch-size12,epoch 143(best,0.9474): 0.961**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**13_ignorebackground,epoch 20(best,0.9818): 0.944**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**10_batch-size6_3,epoch 41(best,0.9477): 0.950**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**11_trainInOneGo_encoder,epoch 133(best,0.9518): 0.962**\n",
        "\n",
        "---\n",
        "\n",
        "**14_fullsizeeval_roadval,epoch 59(best,0.9136): 0.952**\n",
        "\n",
        "---\n",
        "\n",
        "**21_batch-size6_weighted_new,epoch 143(best,0.9483): 0.962**\n",
        "\n",
        "---\n",
        "\n",
        "**22_batch-size6_roadval_weighted_new,epoch 135(best,0.9311): 0.960**\n"
      ]
    },
    {
      "metadata": {
        "id": "j65c42cp0Epo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/eval/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "InBplfj6uJbz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import importlib\n",
        "\n",
        "from PIL import Image\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, CenterCrop, Normalize, Resize\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "from dataset import cityscapes\n",
        "from erfnet import ERFNet\n",
        "from transform import Relabel, ToLabel, Colorize\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "image_transform = ToPILImage()\n",
        "input_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToTensor(),\n",
        "    #Normalize([.485, .456, .406], [.229, .224, .225]),\n",
        "])\n",
        "target_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToLabel(),\n",
        "    Relabel(255, 19),   #ignore label to 19\n",
        "])\n",
        "\n",
        "cityscapes_trainIds2labelIds = Compose([\n",
        "    Relabel(0, 7),\n",
        "    Relabel(1, 0),\n",
        "    ToPILImage(),\n",
        "    #Resize(1024, Image.NEAREST),\n",
        "])\n",
        "def evalEncoderValset():\n",
        "    up = torch.nn.Upsample(scale_factor=16, mode='bilinear')\n",
        "    up = up.cuda()\n",
        "\n",
        "    modelpath = \"/content/erfnet_pytorch/trained_models/\" + \"erfnet.py\"\n",
        "    weightspath = \"/content/drive/erfnet_checkpoints/21_batch-size6_weighted_new/\" + \"model_encoder_best.pth\"\n",
        "\n",
        "    print (\"Loading model: \" + modelpath)\n",
        "    print (\"Loading weights: \" + weightspath)\n",
        "\n",
        "    #Import ERFNet model from the folder\n",
        "    #Net = importlib.import_module(modelpath.replace(\"/\", \".\"), \"ERFNet\")\n",
        "    model = ERFNet(NUM_CLASSES)\n",
        "\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    if (not False):\n",
        "        model = model.cuda()\n",
        "\n",
        "    #model.load_state_dict(torch.load(args.state))\n",
        "    #model.load_state_dict(torch.load(weightspath)) #not working if missing key\n",
        "\n",
        "    def load_my_state_dict(model, state_dict):  #custom function to load model when not all dict elements\n",
        "        own_state = model.state_dict()\n",
        "        for name, param in state_dict.items():\n",
        "            if name not in own_state:\n",
        "                 continue\n",
        "            own_state[name].copy_(param)\n",
        "        return model\n",
        "\n",
        "    model = load_my_state_dict(model, torch.load(weightspath))\n",
        "    print (\"Model and weights LOADED successfully\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if(not os.path.exists(\"/content/datasets/cityscapes/\")):\n",
        "        print (\"Error: datadir could not be loaded\")\n",
        "\n",
        "\n",
        "    loader = DataLoader(cityscapes(\"/content/datasets/cityscapes/\", input_transform_cityscapes, target_transform_cityscapes, subset=\"val\"),\n",
        "        num_workers=4, batch_size=1, shuffle=False)\n",
        "\n",
        "    for step, (images, labels, filename, filenameGt) in enumerate(loader):\n",
        "        \n",
        "        if (not False):\n",
        "            images = images.cuda()\n",
        "            #labels = labels.cuda()\n",
        "\n",
        "        inputs = Variable(images, volatile=True)\n",
        "        #targets = Variable(labels, volatile=True)\n",
        "        outputs = model(inputs,only_encode=True)\n",
        "        outputs = up(outputs)\n",
        "\n",
        "        label = outputs[0].max(0)[1].byte().cpu().data\n",
        "        label_cityscapes = cityscapes_trainIds2labelIds(label.unsqueeze(0))\n",
        "        #print (numpy.unique(label.numpy()))  #debug\n",
        "\n",
        "        filenameSave = \"/content/erfnet_pytorch/eval/save_results/\" + filename[0].split(\"leftImg8bit/\")[1]\n",
        "        os.makedirs(os.path.dirname(filenameSave), exist_ok=True)\n",
        "        #image_transform(label.byte()).save(filenameSave)\n",
        "        label_cityscapes.save(filenameSave)\n",
        "\n",
        "        print (step, filenameSave)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CXNevisFuJbz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evalEncoderValset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HKzs-QNguJb1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "8HvYFUMyuJb1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('/content/erfnet_pytorch/eval/save_results/val/munster/munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vf5nuBQluJb3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "61ONDicUuJb3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/erfnet_pytorch/eval/save_results/val/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zCoWsGdPuJb5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x1PfzD-JuJb6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kuqiJ12Dw2Kh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test retrained decoder (val dataset, nn upsampling) 0.971\n",
        "\n",
        "**01_batch-size6,epoch 63(best,0.9464): 0.953**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**02_batch-size6_state,epoch 138(best,0.9441): 0.962**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**03_noencoder,epoch 106: 0.963**\n",
        "\n",
        "**03_noencoder,epoch 133 (best,0.9461): 0.966**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**04_pretrainedenc,epoch 65: 0.964**\n",
        "\n",
        "**04_pretrainedenc,epoch 137: 0.964**\n",
        "\n",
        "**04_pretrainedenc,epoch 147(best,0.9503): 0.967**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**05_batch-size6_pretrained,epoch 134(best,0.9466): 0.961**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**06_pretrainedenc_2,epoch 64: 0.960**\n",
        "\n",
        "**06_pretrainedenc_2,epoch 88(best,0.9501): 0.970**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**11_trainInOneGo_decoder,epoch 59: 0.960**\n",
        "\n",
        "**11_trainInOneGo_decoder,epoch 133(best,0.9504): 0.962**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**08_batch-size6_2,epoch 134(best,0.9455): 0.962**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**15_pretrainedenc_weighted,epoch 73: 0.965**\n",
        "\n",
        "**15_pretrainedenc_weighted,epoch 97: 0.962**\n",
        "\n",
        "**15_pretrainedenc_weighted,epoch 134(best,0.9486): 0.963**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**16_pretrained_fullsizeeval_roadval,epoch 117(best,0.9382): 0.971**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**17_pretrained_fullsizeeval_roadval_weighted,epoch 138(best,0.9302): 0.962**\n",
        "\n",
        "---\n",
        "\n",
        "**18_pretrainedenc_roadval,epoch 81(best,0.9340): 0.959**\n",
        "\n",
        "---\n",
        "\n",
        "**19_pretrainedenc_weighted_new,epoch 34(best,0.9514): 0.969**\n",
        "\n",
        "---\n",
        "\n",
        "**20_pretrainedenc_roadval_weighted_new,epoch 118(best,0.9323): 0.960**\n",
        "\n",
        "---\n",
        "\n",
        "**21_batch-size6_weighted_new,epoch 120(best,0.9441): 0.964**\n",
        "\n",
        "---\n",
        "\n",
        "**22_batch-size6_roadval_weighted_new,epoch 63: 0.954**\n",
        "\n",
        "**22_batch-size6_roadval_weighted_new,epoch 78: 0.961**\n",
        "\n",
        "**22_batch-size6_roadval_weighted_new,epoch 120(best,0.9328): 0.967**\n"
      ]
    },
    {
      "metadata": {
        "id": "8cpqXRdZ0Fxw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/eval/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uZWo85_Qw2Kj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import importlib\n",
        "\n",
        "from PIL import Image\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, CenterCrop, Normalize, Resize\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "from dataset import cityscapes\n",
        "from erfnet import ERFNet\n",
        "from transform import Relabel, ToLabel, Colorize\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "image_transform = ToPILImage()\n",
        "input_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToTensor(),\n",
        "    #Normalize([.485, .456, .406], [.229, .224, .225]),\n",
        "])\n",
        "target_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToLabel(),\n",
        "    Relabel(255, 19),   #ignore label to 19\n",
        "])\n",
        "\n",
        "cityscapes_trainIds2labelIds = Compose([\n",
        "    Relabel(0, 7),\n",
        "    Relabel(1, 0),\n",
        "    ToPILImage(),\n",
        "    #Resize(1024, Image.NEAREST),\n",
        "])\n",
        "def evalEncoderValset():\n",
        "    up = torch.nn.Upsample(scale_factor=2, mode='nearest')\n",
        "    up = up.cuda()\n",
        "\n",
        "    modelpath = \"/content/erfnet_pytorch/trained_models/\" + \"erfnet.py\"\n",
        "    weightspath = \"/content/drive/erfnet_checkpoints/22_batch-size6_roadval_weighted_new/\" + \"model_best.pth\"\n",
        "\n",
        "    print (\"Loading model: \" + modelpath)\n",
        "    print (\"Loading weights: \" + weightspath)\n",
        "\n",
        "    #Import ERFNet model from the folder\n",
        "    #Net = importlib.import_module(modelpath.replace(\"/\", \".\"), \"ERFNet\")\n",
        "    model = ERFNet(NUM_CLASSES)\n",
        "\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    if (not False):\n",
        "        model = model.cuda()\n",
        "\n",
        "    #model.load_state_dict(torch.load(args.state))\n",
        "    #model.load_state_dict(torch.load(weightspath)) #not working if missing key\n",
        "\n",
        "    def load_my_state_dict(model, state_dict):  #custom function to load model when not all dict elements\n",
        "        own_state = model.state_dict()\n",
        "        for name, param in state_dict.items():\n",
        "            if name not in own_state:\n",
        "                 continue\n",
        "            own_state[name].copy_(param)\n",
        "        return model\n",
        "\n",
        "    model = load_my_state_dict(model, torch.load(weightspath))\n",
        "    print (\"Model and weights LOADED successfully\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if(not os.path.exists(\"/content/datasets/cityscapes/\")):\n",
        "        print (\"Error: datadir could not be loaded\")\n",
        "\n",
        "\n",
        "    loader = DataLoader(cityscapes(\"/content/datasets/cityscapes/\", input_transform_cityscapes, target_transform_cityscapes, subset=\"val\"),\n",
        "        num_workers=4, batch_size=1, shuffle=False)\n",
        "\n",
        "    for step, (images, labels, filename, filenameGt) in enumerate(loader):\n",
        "        \n",
        "        if (not False):\n",
        "            images = images.cuda()\n",
        "            #labels = labels.cuda()\n",
        "\n",
        "        inputs = Variable(images, volatile=True)\n",
        "        #targets = Variable(labels, volatile=True)\n",
        "        outputs = model(inputs,only_encode=False)\n",
        "        outputs = up(outputs)\n",
        "\n",
        "        label = outputs[0].max(0)[1].byte().cpu().data\n",
        "        label_cityscapes = cityscapes_trainIds2labelIds(label.unsqueeze(0))\n",
        "        #print (numpy.unique(label.numpy()))  #debug\n",
        "\n",
        "        filenameSave = \"/content/erfnet_pytorch/eval/save_results/\" + filename[0].split(\"leftImg8bit/\")[1]\n",
        "        os.makedirs(os.path.dirname(filenameSave), exist_ok=True)\n",
        "        #image_transform(label.byte()).save(filenameSave)\n",
        "        label_cityscapes.save(filenameSave)\n",
        "\n",
        "        print (step, filenameSave)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FKUL3JuPw2Kl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evalEncoderValset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_6in9O9Tw2Kn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "xl7wxsEnw2Kn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('/content/erfnet_pytorch/eval/save_results/val/munster/munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rMEH18oAw2Ko",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "e-AsU0-Sw2Ko",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/erfnet_pytorch/eval/save_results/val/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TY9Oaj7Ow2Kq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pHsTkkXcw2Ks",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PdMP-WHIw2Kt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test retrained decoder (val dataset, bilinear upsampling) 0.972\n",
        "\n",
        "**01_batch-size6,epoch 63(best,0.9464): 0.953**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**02_batch-size6_state,epoch 138(best,0.9441): 0.962**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**03_noencoder,epoch 106: 0.963**\n",
        "\n",
        "**03_noencoder,epoch 133 (best,0.9461): 0.967**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**04_pretrainedenc,epoch 65: 0.965**\n",
        "\n",
        "**04_pretrainedenc,epoch 137: 0.965**\n",
        "\n",
        "**04_pretrainedenc,epoch 147(best,0.9503): 0.967**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**05_batch-size6_pretrained,epoch 134(best,0.9466): 0.962**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**06_pretrainedenc_2,epoch 64: 0.961**\n",
        "\n",
        "**06_pretrainedenc_2,epoch 88(best,0.9501): 0.970**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**11_trainInOneGo_decoder,epoch 59: 0.960**\n",
        "\n",
        "**11_trainInOneGo_decoder,epoch 133(best,0.9504): 0.962**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**08_batch-size6_2,epoch 134(best,0.9455): 0.963**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**15_pretrainedenc_weighted,epoch 73: 0.966**\n",
        "\n",
        "**15_pretrainedenc_weighted,epoch 134(best,0.9486): 0.964**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**16_pretrained_fullsizeeval_roadval,epoch 117(best,0.9382): 0.972**\n",
        "\n",
        "---\n",
        "\n",
        "**17_pretrained_fullsizeeval_roadval_weighted,epoch 138(best,0.9302): 0.963**\n",
        "\n",
        "---\n",
        "\n",
        "**18_pretrainedenc_roadval,epoch 81(best,0.9340): 0.960**\n",
        "\n",
        "---\n",
        "\n",
        "**19_pretrainedenc_weighted_new,epoch 34(best,0.9514): 0.969**\n",
        "\n",
        "---\n",
        "\n",
        "**20_pretrainedenc_roadval_weighted_new,epoch 118(best,0.9323): 0.961**\n",
        "\n",
        "---\n",
        "\n",
        "**21_batch-size6_weighted_new,epoch 120(best,0.9441): 0.965**\n",
        "\n",
        "---\n",
        "\n",
        "**22_batch-size6_roadval_weighted_new,epoch 63: 0.955**\n",
        "\n",
        "**22_batch-size6_roadval_weighted_new,epoch 78: 0.961**\n",
        "\n",
        "**22_batch-size6_roadval_weighted_new,epoch 120(best,0.9328): 0.968**"
      ]
    },
    {
      "metadata": {
        "id": "59gZSJ340Gb3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/eval/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oulgJN0Dw2Kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import importlib\n",
        "\n",
        "from PIL import Image\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, CenterCrop, Normalize, Resize\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "from dataset import cityscapes\n",
        "from erfnet import ERFNet\n",
        "from transform import Relabel, ToLabel, Colorize\n",
        "\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "image_transform = ToPILImage()\n",
        "input_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToTensor(),\n",
        "    #Normalize([.485, .456, .406], [.229, .224, .225]),\n",
        "])\n",
        "target_transform_cityscapes = Compose([\n",
        "    Resize(512),\n",
        "    ToLabel(),\n",
        "    Relabel(255, 19),   #ignore label to 19\n",
        "])\n",
        "\n",
        "cityscapes_trainIds2labelIds = Compose([\n",
        "    Relabel(0, 7),\n",
        "    Relabel(1, 0),\n",
        "    ToPILImage(),\n",
        "    #Resize(1024, Image.NEAREST),\n",
        "])\n",
        "def evalEncoderValset():\n",
        "    up = torch.nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "    up = up.cuda()\n",
        "\n",
        "    modelpath = \"/content/erfnet_pytorch/trained_models/\" + \"erfnet.py\"\n",
        "    weightspath = \"/content/drive/erfnet_checkpoints/22_batch-size6_roadval_weighted_new/\" + \"model_best.pth\"\n",
        "\n",
        "    print (\"Loading model: \" + modelpath)\n",
        "    print (\"Loading weights: \" + weightspath)\n",
        "\n",
        "    #Import ERFNet model from the folder\n",
        "    #Net = importlib.import_module(modelpath.replace(\"/\", \".\"), \"ERFNet\")\n",
        "    model = ERFNet(NUM_CLASSES)\n",
        "\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    if (not False):\n",
        "        model = model.cuda()\n",
        "\n",
        "    #model.load_state_dict(torch.load(args.state))\n",
        "    #model.load_state_dict(torch.load(weightspath)) #not working if missing key\n",
        "\n",
        "    def load_my_state_dict(model, state_dict):  #custom function to load model when not all dict elements\n",
        "        own_state = model.state_dict()\n",
        "        for name, param in state_dict.items():\n",
        "            if name not in own_state:\n",
        "                 continue\n",
        "            own_state[name].copy_(param)\n",
        "        return model\n",
        "\n",
        "    model = load_my_state_dict(model, torch.load(weightspath))\n",
        "    print (\"Model and weights LOADED successfully\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if(not os.path.exists(\"/content/datasets/cityscapes/\")):\n",
        "        print (\"Error: datadir could not be loaded\")\n",
        "\n",
        "\n",
        "    loader = DataLoader(cityscapes(\"/content/datasets/cityscapes/\", input_transform_cityscapes, target_transform_cityscapes, subset=\"val\"),\n",
        "        num_workers=4, batch_size=1, shuffle=False)\n",
        "\n",
        "    for step, (images, labels, filename, filenameGt) in enumerate(loader):\n",
        "        \n",
        "        if (not False):\n",
        "            images = images.cuda()\n",
        "            #labels = labels.cuda()\n",
        "\n",
        "        inputs = Variable(images, volatile=True)\n",
        "        #targets = Variable(labels, volatile=True)\n",
        "        outputs = model(inputs,only_encode=False)\n",
        "        outputs = up(outputs)\n",
        "\n",
        "        label = outputs[0].max(0)[1].byte().cpu().data\n",
        "        label_cityscapes = cityscapes_trainIds2labelIds(label.unsqueeze(0))\n",
        "        #print (numpy.unique(label.numpy()))  #debug\n",
        "\n",
        "        filenameSave = \"/content/erfnet_pytorch/eval/save_results/\" + filename[0].split(\"leftImg8bit/\")[1]\n",
        "        os.makedirs(os.path.dirname(filenameSave), exist_ok=True)\n",
        "        #image_transform(label.byte()).save(filenameSave)\n",
        "        label_cityscapes.save(filenameSave)\n",
        "\n",
        "        print (step, filenameSave)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DTK3p_CZw2Kz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "evalEncoderValset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e_j4666cw2K1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "s9exmSITw2K1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('/content/erfnet_pytorch/eval/save_results/val/lindau/lindau_000004_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PMaWDoz5w2K2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "9y2zs_HOw2K2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/erfnet_pytorch/eval/save_results/val/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "el-NhIkRw2K4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ikG1Z7SGw2K7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S59eLb6eMS7c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# retrain encoder (binary)"
      ]
    },
    {
      "metadata": {
        "id": "nUTBYdB0vTuj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder batch-size 6"
      ]
    },
    {
      "metadata": {
        "id": "3HA3KmmMAZy4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "eBcX-jIlAor2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wouDPwy5APNY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size6_3/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HavdqwjZAcY4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "wwNz5dyBAo7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sbw7X6m1N14s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size6_3/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cXfH0efnAjoJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder batch-size 12"
      ]
    },
    {
      "metadata": {
        "id": "8Ab7koNsAjoJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "4TerVcPLAjoJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gfl3aCTWAjoM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size12/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w3gGiYQ8AjoM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "EPP1jKekAjoN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qqmGrRb_AjoO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size12/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 12 --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Et9d6aIiAlf5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder batch-size 6, weighted"
      ]
    },
    {
      "metadata": {
        "id": "8ZDKeHrrAlf5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "j2p8JafaAlf6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jcGAJcGeAlf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size6_weighted/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --weighted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HS6INIKWAlf7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "z3JfF7ecAlf8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Pe7QhPpAlf9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size6_weighted/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --resume --weighted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GA_drzis6oxB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder batch-size 6 fullsizeeval"
      ]
    },
    {
      "metadata": {
        "id": "yVX_UzMz6oxB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "EJ9P2RZh6oxC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N4x8Htu86oxD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_fullsizeeval.py --savedir /content/drive/erfnet_checkpoints/fullsizeeval/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYAAr-d26oxE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "fF3Nu6L-6oxE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6KcCxuw6oxF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_fullsizeeval.py --savedir /content/drive/erfnet_checkpoints/fullsizeeval/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZImCvZ_xGHrQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder batch-size 6 fullsizeeval ignore background"
      ]
    },
    {
      "metadata": {
        "id": "eCEkeaxUGHrR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "sy0NoAkFGHrR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cd0AdkphGHrT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_fullsizeeval.py --savedir /content/drive/erfnet_checkpoints/fullsizeeval_ignorebackground/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --ignoreindex 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UVlcBTftGHrU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "IQP2fGf8GHrU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TU8QuEwaGHrW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_fullsizeeval.py --savedir /content/drive/erfnet_checkpoints/fullsizeeval_ignorebackground/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --ignoreindex 1 --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g-kAu-e_hk1G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder batch-size 6 ignore background"
      ]
    },
    {
      "metadata": {
        "id": "TVZ75iUZhk1G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "WpKX8-9Chk1H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRLGkb5Fhk1I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/ignorebackground/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --ignoreindex 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZGxTU7mQhk1J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "gDBaMDWghk1J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PyjtdwNohk1K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/ignorebackground/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --resume --ignoreindex 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oQ1LnHKboiZg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder batch-size 6 20 classes"
      ]
    },
    {
      "metadata": {
        "id": "Gx8hgK8toiZh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "iBI4r-0toiZh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "isMzW-96oiZj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main.py --savedir /content/drive/erfnet_checkpoints/20classes/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LUDqRV2SoiZl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "_iaJ7APZoiZl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dxsrmsY2oiZp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/20classes/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3uvIhNI-ZHY6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder trainInOneGo"
      ]
    },
    {
      "metadata": {
        "id": "9gtXsHEYZHY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "g4Wp9fdlZHY7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mb_b_7EeZHY7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/trainInOneGo/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --trainInOneGo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mQAXvf-mZHY8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "E2O2AJVJZHY8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "go_tLg1BZHY9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/trainInOneGo/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --trainInOneGo --resume "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K_5BWsbSHz9m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder batch-size 6 fullsizeeval roadval"
      ]
    },
    {
      "metadata": {
        "id": "FFONnk0_Hz9n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "fLFcBS-IHz9n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uYSL-QpbHz9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_fullsizeeval_roadval.py --savedir /content/drive/erfnet_checkpoints/fullsizeeval_roadval/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o4IZLePGHz9q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "Mx54hsbLHz9r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "27DEkNc4Hz9s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_fullsizeeval_roadval.py --savedir /content/drive/erfnet_checkpoints/fullsizeeval_roadval/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V-k9mqBWAEYR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder batch-size6_roadval_weighted_new"
      ]
    },
    {
      "metadata": {
        "id": "F475L_2pAEYY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "emDecjDZAEYb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G608sa59AEYh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_roadval.py --savedir /content/drive/erfnet_checkpoints/batch-size6_roadval_weighted_new/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --weighted_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuL1iPt-AEYn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "uEe5mFTxAEYo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FIwMYrdgAEYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_roadval.py --savedir /content/drive/erfnet_checkpoints/batch-size6_roadval_weighted_new/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --weighted_new --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kX1oDrILRSLm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#retrain decoder (binary)"
      ]
    },
    {
      "metadata": {
        "id": "mXChuFGRm_8o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##train decoder batch-size 6"
      ]
    },
    {
      "metadata": {
        "id": "lIY5wAcem_8p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "ZI32UANrm_8p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QAkcXanGm_8r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size6_2/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0oj3QIdpm_8s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "dtiBVbPkm_8t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z2DUFFdhm_8u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size6_2/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UUIUbZ1am_8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##train decoder batch-size 12"
      ]
    },
    {
      "metadata": {
        "id": "0bAHfpgZm_8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "QQnHWPVem_8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pv1GBtbPm_8z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size12/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 12 --decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N13zbVOlm_81",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "8QtTl8_Ym_81",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bBeMzp-Am_83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size12/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 12 --decoder --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ujoojgdm_85",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##train decoder batch-size 6, weighted"
      ]
    },
    {
      "metadata": {
        "id": "j7H8ksr8m_85",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "ValfkGG2m_85",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LGVxoL4Jm_87",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size6_weighted/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --weighted --decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DHI5N3vbm_8_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "Jh8gh8OBm_8_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZEWXE1zJm_9A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size6_weighted/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --weighted --decoder --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dgvUwZWxTU33",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##train decoder without encoder"
      ]
    },
    {
      "metadata": {
        "id": "zayXVo8gTU34",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "GWz2JrD8TU34",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0pOAzLGWTU35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/noencoder/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42vYvCzPTU35",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "4NE-Sj17TU36",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2P6oQXeBTU37",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/noencoder/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JO6Vuu-pwgVJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##train decoder with encoder pretrained on imagenet"
      ]
    },
    {
      "metadata": {
        "id": "aXcl3YcdwgVJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "jTQwjxD2wgVJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MH65yGLOwgVK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/pretrainedenc_2/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5UONrHCrwgVM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "ZIcRDtP3wgVM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tg_kBJNqwgVN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/pretrainedenc_2/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\" --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yDSNwEqt8JM4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##train decoder with encoder pretrained on cityscapes"
      ]
    },
    {
      "metadata": {
        "id": "wDhFj_xR8JM4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "Rn9JX6KK8JM4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gRrfMFtr8JM5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size6_2/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder  --state \"/content/drive/erfnet_checkpoints/batch-size6_2/model_best_enc.pth.tar\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Fl93zzl8JM6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "T7NTEZvB8JM6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gNJyfYVx8JM8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size6_2/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --resume "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IQfqvqUTpZd4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##train decoder with encoder pretrained on imagenet 20 classes"
      ]
    },
    {
      "metadata": {
        "id": "PQ5uy_6upZd5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "IVKDdhFPpZd5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bWPTUME7pZd7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main.py --savedir /content/drive/erfnet_checkpoints/pretrainedenc20classes/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yJhpzOLapZd7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "45oZpfUYpZd8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z48ggTslpZd9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main.py --savedir /content/drive/erfnet_checkpoints/pretrainedenc20classes/ --datadir /content/datasets/cityscapes/ --num-epochs 300 --batch-size 6 --decoder --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\" --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JD9mZD63CO4l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain decoder batch-size 6 fullsizeeval roadval with encoder pretrained on imagenet"
      ]
    },
    {
      "metadata": {
        "id": "VIp_6RrQCO4l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "lBZFFe9SCO4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H3m1vXFkCO4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_fullsizeeval_roadval.py --savedir /content/drive/erfnet_checkpoints/pretrained_fullsizeeval_roadval/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1uDG84H6CO4q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "MbWJXYPpCO4q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1LmTieaCO4q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_fullsizeeval_roadval.py --savedir /content/drive/erfnet_checkpoints/pretrained_fullsizeeval_roadval/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\" --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G15P4OgaLgiP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain decoder batch-size 6 fullsizeeval roadval weighted with encoder pretrained on imagenet"
      ]
    },
    {
      "metadata": {
        "id": "Y66RjV9RLgiP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "cMfkeEESLgiQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ppzV8NteLgiS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_fullsizeeval_roadval.py --savedir /content/drive/erfnet_checkpoints/pretrained_fullsizeeval_roadval_weighted/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --weighted --decoder --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19ve-ak1LgiV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "iwrNb3F7LgiW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u-T2Mvh2LgiX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_fullsizeeval_roadval.py --savedir /content/drive/erfnet_checkpoints/pretrained_fullsizeeval_roadval_weighted/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --weighted --decoder --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\" --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hMxsxaXTDf22",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain decoder batch-size 6 weighted with encoder pretrained on imagenet"
      ]
    },
    {
      "metadata": {
        "id": "KDcWzYIJDf23",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "6DRqmNkmDf23",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s9fy-GD0Df24",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/pretrainedenc_weighted/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\" --weighted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eYBHSe6ODf27",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "LRZGnAHrDf27",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "845i9JW8Df28",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/pretrainedenc_weighted/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\" --resume --weighted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_3QDyU2SArdG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain decoder batch-size6_weighted_new"
      ]
    },
    {
      "metadata": {
        "id": "a6O0d3MWArdL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "XcYXI0WsArdO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BO8fMLNKArdZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size6_weighted_new/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --weighted_new --decoder --state /content/drive/erfnet_checkpoints/batch-size6_weighted_new/model_best_enc.pth.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nDmMIV1EArdf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "SA15JA-qArdi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BxCsZtdoArdp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary.py --savedir /content/drive/erfnet_checkpoints/batch-size6_weighted_new/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --weighted_new --decoder --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KBhzRKqXBdfh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain decoder pretrainedenc_roadval"
      ]
    },
    {
      "metadata": {
        "id": "T0PFZfF0Bdfk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "rUPDrfqxBdfn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mCB_aHnxBdfu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_roadval.py --savedir /content/drive/erfnet_checkpoints/pretrainedenc_roadval/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q5jc_bQEBdf0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "AoI2ccL5Bdf5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R81w_-f7Bdf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_roadval.py --savedir /content/drive/erfnet_checkpoints/pretrainedenc_roadval/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\" --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rdy7NaJ_B_uo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain decoder pretrainedenc_roadval_weighted_new"
      ]
    },
    {
      "metadata": {
        "id": "gvrTSVsTB_us",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "nmG09uvcB_uu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PanwPyE3B_u2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_roadval.py --savedir /content/drive/erfnet_checkpoints/pretrainedenc_roadval_weighted_new/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --weighted_new --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8AW1rqdWB_u8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "55XUj0-GB_u-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JMiX9UyzB_vI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_roadval.py --savedir /content/drive/erfnet_checkpoints/pretrainedenc_roadval_weighted_new/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --decoder --weighted_new --pretrainedEncoder \"../trained_models/erfnet_encoder_pretrained.pth.tar\" --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1HSRjdX9VCP_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain decoder batch-size6_roadval_weighted_new"
      ]
    },
    {
      "metadata": {
        "id": "0LCu0XaoVCQA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "vq1jmtGoVCQB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BXYT96HKVCQB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_roadval.py --savedir /content/drive/erfnet_checkpoints/batch-size6_roadval_weighted_new/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --weighted_new --decoder --state /content/drive/erfnet_checkpoints/batch-size6_roadval_weighted_new/model_best_enc.pth.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iPrhGPcAVCQC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "u566TiHuVCQC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MkYNkTfkVCQD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_binary_roadval.py --savedir /content/drive/erfnet_checkpoints/batch-size6_roadval_weighted_new/ --datadir /content/datasets/cityscapes/ --num-epochs 150 --batch-size 6 --weighted_new --decoder --resume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VkSafjpt8eNf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run evaluations"
      ]
    },
    {
      "metadata": {
        "id": "0gr4mqGa_Rm8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/erfnet_pytorch/eval/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d58jbFUQnoSA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python eval_cityscapes_color.py --datadir /content/datasets/cityscapes/ --subset val --num-workers 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EUB9jtayEDH4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('./save_color/val/munster/munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H7y-6KCzoD9J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python eval_iou.py --datadir /content/datasets/cityscapes/ --subset val --num-workers 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "etgXjnzSE76u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python eval_cityscapes_server.py --datadir /content/datasets/cityscapes/ --subset val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VvI7Jf_VFMpx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('./save_results/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}